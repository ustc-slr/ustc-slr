<!DOCTYPE html>
<html lang="en">
<head>
	<meta charset="UTF-8">
	<title>Chinese SLR Dataset</title>
	<!--<link href="../../configs/css/mystyle.css" rel="stylesheet">-->
	<link rel="stylesheet" href="../../configs/style/jemdoc.css" type="text/css">

</head>
<body style="width:95%;margin-left:auto;margin-right:auto;">


<h1 align="center"; style="font-size:36px; color: #000000; border-bottom: none">Chinese Sign Language Recognition Dataset</h1>
<h2 align="center"; style="color: #000000; border-bottom: none">University of Science and Technology of China (USTC)</h2>
<h3 align="center"; style="color: #000000; border-bottom: none">Multimedia Computing & Communication, SLR Group</h3>
<hr class="sec_line">

<h2>Download (<i><font color="#FF0000">*Important</font> </i>)</h2>
<p class="textBlock">
	The download links in this webpage are not available anymore. To access the download link of the dataset, please contact us with emails. We will send you the license agreement as well as the download links.
</p>

<h2>Introduction</h2>
<p class="textBlock">
	We have two Chinese sign language datasets for isolated Sign Language Recognition and continuous Sign Language Recognition, respectively. Both datasets are collected with Kinect 2.0 by 50 signers. Each signer perfors 5 times for every word (sentence). The sign videos are recorded with 30<i>fps</i>. The distance between the signers and Kinect is about 1.5 meters. Each instance in both datasets contains <b>RGB videos</b>, <b>depth videos</b>, and <b>3D joints information</b> of the signer.
<br><br>
	Since the dataset is recorded with Microsoft Kinect, there are three data modalities available:
	<ol>
		<li>RGB videos with resolution of 1280 x 720 pixels and frame rate of 30 fps.</li>
		<li>Depth videos with resolution of 512x 424 pixels and frame rate of 30 fps.</li>
		<li>Twenty-five skeleton joints locations of each frame.</li>
	</ol>
</p>

<h2>Isolated SLR</h2>
<p class="textBlock">
	If you use this Chinese isolated SLR dataset in your research, please cite the following papers: 
	<ul>
		<li>Jihai Zhang, Wengang Zhou, Chao Xie, Junfu Pu, and Houqiang Li, "Chinese Sign Language Recognition with Adaptive HMM," <i>IEEE International Conference on Multimedia and Expo (ICME)</i>, 2016.</li>
		<li>Junfu Pu, Wengang Zhou, and Houqiang Li, "Sign Language Recognition with Multi-modal Features," <i>Pacific-Rim Conference on Multimedia (PCM)</i>, 2016.</li>
		<li>Tao Liu, Wengang Zhou, and Houqiang Li, "Sign Language Recognition with Long Short Term Memory," <i>IEEE International Conference on Image Processing (ICIP)</i>, 2016.</li>
		<li>Junfu Pu, Wengang Zhou, Jihai Zhang, and Houqiang Li, "Sign Language Recognition Based on Trajectory Modeling with HMMs," <i>International Conference on Multimedia Modelling (MMM)</i>, 2016.</li>
	</ul>
</p>

<p class="textBlock">
	The isolated SLR dataset contains 500 Chinese sign words. Each sign video is performed by 50 signers with 5 times. Hence, there are 250 instances for each sign word.
	<br><br>
	You can download the RGB and Depth videos of the dataset here <a href="https://pan.baidu.com/s/1tdUdI_3Ius44__d9PzVRCA" target="_blank">Isolated SLR500 (RGB & Depth, 1 time each signer)</a>, or <a href="https://pan.baidu.com/s/1MrJK66VBr65zBmYR21XBXg" target="_blank">Isolated SLR500 (RGB, 5 times each signer)</a> [password: rvux].
	<br>
	Check the instruction to download here. <a href="http://home.ustc.edu.cn/~hagjie/" target="_blank">[How]</a>
	<br>
	Besides, the signer's skeleton joint information is available here <a href="https://pan.baidu.com/s/1rbxv2PAulaWgMKAv3hVNUg" target="_blank">Isolated SLR500 (Joints)</a>. [password: fwt7]
</p>

<h2>Continuous SLR</h2>
<p class="textBlock">
	If you use this Chinese continuous SLR dataset in your research, please cite the following papers:
	<ul>
		<li>Junfu Pu, Wengang Zhou, and Houqiang Li, "Iterative Alignment Network for Continuous Sign Language Recognition," <i>Conference on Computer Vision and Pattern Recognition (CVPR)</i>, 2019.</li>
		<li>Hao Zhou, Wengang Zhou, and Houqiang Li, "Dynamic Pseudo Label Decoding for Continuous Sign Language Recognition," <i>International Conference on Multimedia and Expo (ICME)</i>, 2019.</li>
		<li>Jie Huang, Wengang Zhou, Qilin Zhang, Houqiang Li and Weiping Li, "Video-based Sign Language Recognition without Temporal Segmentation," <i>AAAI Conference on Artificial Intelligence (AAAI)</i>, 2018.</li>
	</ul>
</p>
<p class="textBlock">
	Besides, you can refer to the following papers for continuous SLR published by our group:
	<ul>
		<li>Junfu Pu, Wengang Zhou, Hezhen Hu, and Houqiang Li, "Boosting Continuous Sign Language Recognition via Cross Modality Augmentation," <i>ACM International Conference on Multimedia (ACM MM)</i>, 2020.</li>
		<li>Junfu Pu, Wengang Zhou, and Houqiang Li, "Dilated Convolutional Network with Iterative Optimization for Continuous Sign Language Recognition," <i>International Joint Conference on Artificial Intelligence (IJCAI)</i>, 2018.</li>
		<li>Dan Guo, Wengang Zhou, Meng Wang, and Houqiang Li, "Hierarchical LSTM for Sign Language Translation," <i>AAAI Conference on Artificial Intelligence (AAAI)</i>, 2018.</li>
	</ul>
</p>

<p class="textBlock">
	The corpus of continuous SLR dataset contains 100 Chinese sentence. There are 250 instances (50signers x 5times) for each sentence.
	<br><br>
	You can download the RGB videos of the continuous SLR dataset here <a href="https://pan.baidu.com/s/1jJgDHMQ" target="_blank">Continuous SLR100 (RGB)</a>. [password: ac52]
	<br>
</p>

<h2>Contact</h2>
<p class="textBlock">
	If you have any questions about the dataset and our papers, please feel free to contact us:
	<ul>
		<li><a href="http://staff.ustc.edu.cn/~lihq/English.html" target="_blank">Houqiang Li</a>, Professor, USTC, lihq AT ustc.edu.cn</li>
		<li><a href="http://staff.ustc.edu.cn/~zhwg" target="_blank">Wengang Zhou</a>, Associate Professor, USTC, zhwg AT ustc.edu.cn</li>
		<li><a href="http://home.ustc.edu.cn/~pjh" target="_blank">Junfu Pu</a>, Ph.D Candidate, USTC, pjh AT mail.ustc.edu.cn</li>
		<li><a href="https://github.com/Rhythmblue" target="_blank">Hao Zhou</a>, Master student, USTC, zhouh156 AT mail.ustc.edu.cn</li>
		<li><a href="" target="_blank">Chengcheng Wei</a>, Master student, USTC, ccwei AT mail.ustc.edu.cn</li>
	</ul>
	You can also visit <a href="../slr/index.html" target="_blank">Visual Sign Language Research Group (VSLRG)</a> for more details about our group and research topics.
</p>


<h2 align="center" style="border-bottom: none"><a href="../../index.html"><b>[Back to Homepage]</b></a></h2>
<hr style="height:1px;border:none;border-top:1px solid #555555;">
<div align="right" style="font-family:verdana;color:#800000">&copy; Junfu Pu 2019 &nbsp&nbsp&nbsp&nbsp&nbsp Last updated on Aug. 7, 2019</div>
<br>
<div style="width:400px;margin:0 auto">
<script type="text/javascript" id="clustrmaps" src="//cdn.clustrmaps.com/map_v2.js?d=jWKtanh3GLIaA7YarJE404P09JqFOL2zKwXMRyyAEBE&cl=ffffff&w=a"></script>
</div>
<p><br><br><br></p>
</body>
</html>